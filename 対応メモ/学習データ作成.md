音の前処理
・サンプリングレートを統一する
    16kHzが一番扱いやすいデータ？　一旦この音に合わせる

・ステレオ or モノラル
    AI観点でいうとモノラルがいいらしい　一旦モノラルに合わせる

・音のこまかさ　ビット深度を統一
    16bitPCMが標準とのことなのでこれに合わせる

ノイズ除去。、音声の明瞭化を実施する必要あり

ピーク時の最大音量の統一
    物によっては音声データの最大音量が異なる。これを避けたい
    統一処理を実施する

1. まずフォーマットと基本条件を揃える

目的：後の処理と学習を安定させる

サンプリングレート統一

例：16kHz / 22.05kHz / 24kHz / 44.1kHz など

モデル側の想定に合わせて統一（TTS・ASRなら 16k〜24kHz が多い）

チャンネル数

モノラル（1ch）に統一することがほとんど

ステレオ → モノラルにダウンミックス

ビット深度

16bit PCM（.wav）にしておくと扱いやすい

2. レベル系：音量とクリッピングの整理

目的：ムラの少ない/扱いやすい音量にする

ノーマライズ

ピークを -1dBFS〜-3dBFS くらいに揃える

ラウドネスノーマライズ

複数ファイルを同じ体感音量にしたい場合

EBU R128 で -23 LUFS とか、学習用途なら -20〜 -16 LUFS 付近に揃えるなど

クリッピング修正（あれば）

元音源が割れている場合のデクリック/デクリップ処理（完全には直らないけど、多少マシに）

3. ノイズ・汚れの除去

目的：モデルや耳にとって邪魔な情報を減らす

ホワイトノイズ・ヒスノイズ

スペクトル減算法 / ノイズプロファイルを使った NR（ノイズリダクション）

ハムノイズ（50/60Hz ブーン）

ノッチフィルタで 50Hz / 60Hz 付近を削る

ポップノイズ / クリック音

デクリック処理（短いピークだけを除去）

環境音が常に乗っている場合

軽めのノイズ抑制（やり過ぎるとロボ声になるので注意）

4. 周波数特性の調整（EQ系）

目的：声を聞き取りやすく / モデルにとって特徴を取りやすく

ハイパスフィルタ

例：80〜120Hz 以下をカット（低い唸り・振動・風音を消す）

ローパスフィルタ

高域ノイズが気になる場合に 16kHz くらいで落とす

軽い EQ

声の帯域（だいたい 300Hz〜4kHz あたり）を少し持ち上げる

ディエッサー

「サ行」の刺さる音（シビランス）を抑える（必要に応じて）

5. 無音・不要区間の処理

目的：無駄な区間を削って効率を上げる

頭と尻尾の無音カット

一定閾値以下の音量が続く部分を削る

長い無音の圧縮

会話やインタビュー系では、長い沈黙を短くしてテンポを整える

VAD（Voice Activity Detection）で話している区間だけ抽出

1本の長いファイル → 音声区間ごとに分割

モデル学習用データ作りにはほぼ必須レベル