"""
éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’å–å¾—ãƒ»åˆ†æã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import os
from pathlib import Path
from typing import Dict, List, Optional, Union

import librosa
import numpy as np
import soundfile as sf


def analyze_audio_file(file_path: str) -> Optional[Dict[str, Union[str, int, float]]]:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°æƒ…å ±ã‚’å–å¾—ã™ã‚‹

    Args:
        file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        éŸ³å£°æƒ…å ±ã®è¾æ›¸ï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
        {
            'filename': ãƒ•ã‚¡ã‚¤ãƒ«å,
            'file_size_mb': ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º(MB),
            'duration': é•·ã•(ç§’),
            'sample_rate': ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ(Hz),
            'channels': ãƒãƒ£ãƒ³ãƒãƒ«æ•°,
            'channel_type': 'ãƒ¢ãƒãƒ©ãƒ«' or 'ã‚¹ãƒ†ãƒ¬ã‚ª' or 'ãƒãƒ«ãƒãƒãƒ£ãƒ³ãƒãƒ«',
            'bit_depth': ãƒ“ãƒƒãƒˆæ·±åº¦(bit),
            'format': ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼,
            'total_samples': ç·ã‚µãƒ³ãƒ—ãƒ«æ•°,
            'peak_amplitude': ãƒ”ãƒ¼ã‚¯æŒ¯å¹…,
            'rms_level': RMS ãƒ¬ãƒ™ãƒ«(dB)
        }
    """
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        if not os.path.exists(file_path):
            print(f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - {file_path}")
            return None

        file_path_obj = Path(file_path)

        # soundfileã§è©³ç´°æƒ…å ±ã‚’å–å¾—
        info = sf.info(file_path)

        # librosã§éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆåˆ†æç”¨ï¼‰
        y, _ = librosa.load(file_path, sr=None, mono=False)

        # ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã®åˆ¤å®š
        if y.ndim == 1:
            channels = 1
            channel_type = "ãƒ¢ãƒãƒ©ãƒ«"
        else:
            channels = y.shape[0]
            if channels == 2:
                channel_type = "ã‚¹ãƒ†ãƒ¬ã‚ª"
            else:
                channel_type = f"ãƒãƒ«ãƒãƒãƒ£ãƒ³ãƒãƒ«({channels}ch)"

        # ãƒ”ãƒ¼ã‚¯æŒ¯å¹…ã¨RMSãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—
        if y.ndim == 1:
            peak_amplitude = float(np.max(np.abs(y)))
            rms_level = float(np.sqrt(np.mean(y**2)))
        else:
            peak_amplitude = float(np.max(np.abs(y)))
            rms_level = float(np.sqrt(np.mean(y**2)))

        # RMSãƒ¬ãƒ™ãƒ«ã‚’dBã«å¤‰æ›ï¼ˆ0ã‚’é¿ã‘ã‚‹ï¼‰
        rms_db = 20 * np.log10(rms_level) if rms_level > 0 else -np.inf

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        file_size_bytes = os.path.getsize(file_path)
        file_size_mb = file_size_bytes / (1024 * 1024)

        # ãƒ“ãƒƒãƒˆæ·±åº¦ã®å–å¾—
        bit_depth = info.subtype_info.split('_')[-1] if info.subtype_info else 'N/A'
        if bit_depth.startswith('PCM'):
            bit_depth = bit_depth.replace('PCM', '')

        return {
            'filename': file_path_obj.name,
            'file_size_mb': round(file_size_mb, 2),
            'duration': round(info.duration, 2),
            'sample_rate': info.samplerate,
            'channels': channels,
            'channel_type': channel_type,
            'bit_depth': bit_depth,
            'format': info.format,
            'total_samples': info.frames,
            'peak_amplitude': round(peak_amplitude, 4),
            'rms_level': round(float(rms_db), 2)
        }

    except (OSError, ValueError, RuntimeError) as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None


def analyze_audio_levels(
    file_path: str
) -> Optional[Dict[str, float]]:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¬ãƒ™ãƒ«æƒ…å ±ã‚’è©³ç´°ã«åˆ†æã™ã‚‹

    Args:
        file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        ãƒ¬ãƒ™ãƒ«æƒ…å ±ã®è¾æ›¸
        {
            'peak_db': ãƒ”ãƒ¼ã‚¯ãƒ¬ãƒ™ãƒ«(dBFS),
            'rms_db': RMSãƒ¬ãƒ™ãƒ«(dBFS),
            'lufs': ãƒ©ã‚¦ãƒ‰ãƒã‚¹(LUFSæ¨å®šå€¤),
            'crest_factor': ã‚¯ãƒ¬ã‚¹ãƒˆãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼(dB),
            'clipping_samples': ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«æ•°,
            'clipping_percentage': ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ç‡(%),
            'dynamic_range': ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãƒ¬ãƒ³ã‚¸(dB),
            'headroom': ãƒ˜ãƒƒãƒ‰ãƒ«ãƒ¼ãƒ (dB)
        }
    """
    try:
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        y, sr = librosa.load(file_path, sr=None, mono=False)

        # ã‚¹ãƒ†ãƒ¬ã‚ªã®å ´åˆã¯å¹³å‡åŒ–
        if y.ndim > 1:
            y = np.mean(y, axis=0)

        # ãƒ”ãƒ¼ã‚¯ãƒ¬ãƒ™ãƒ«ï¼ˆdBFSï¼‰
        peak_amplitude = np.max(np.abs(y))
        peak_db = 20 * np.log10(peak_amplitude) if peak_amplitude > 0 else -np.inf

        # RMSãƒ¬ãƒ™ãƒ«ï¼ˆdBFSï¼‰
        rms = np.sqrt(np.mean(y**2))
        rms_db = 20 * np.log10(rms) if rms > 0 else -np.inf

        # ãƒ©ã‚¦ãƒ‰ãƒã‚¹ï¼ˆç°¡æ˜“LUFSæ¨å®šï¼‰
        lufs_estimate = rms_db - 23.0

        # ã‚¯ãƒ¬ã‚¹ãƒˆãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ï¼ˆãƒ”ãƒ¼ã‚¯ã¨RMSã®æ¯”ï¼‰
        crest_factor = peak_db - rms_db

        # ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°æ¤œå‡ºï¼ˆæŒ¯å¹…ãŒ0.99ä»¥ä¸Šã®ã‚µãƒ³ãƒ—ãƒ«ï¼‰
        clipping_threshold = 0.99
        clipping_samples = np.sum(np.abs(y) >= clipping_threshold)
        clipping_percentage = (clipping_samples / len(y)) * 100

        # ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãƒ¬ãƒ³ã‚¸
        frame_length = sr
        hop_length = sr // 2
        frame_rms = librosa.feature.rms(y=y, frame_length=int(frame_length), hop_length=int(hop_length))[0]
        noise_floor = np.percentile(frame_rms, 5)
        noise_floor_db = 20 * np.log10(noise_floor) if noise_floor > 0 else -np.inf
        dynamic_range = peak_db - noise_floor_db

        # ãƒ˜ãƒƒãƒ‰ãƒ«ãƒ¼ãƒ 
        headroom = 0.0 - peak_db

        return {
            'peak_db': round(peak_db, 2),
            'rms_db': round(rms_db, 2),
            'lufs': round(lufs_estimate, 2),
            'crest_factor': round(crest_factor, 2),
            'clipping_samples': int(clipping_samples),
            'clipping_percentage': round(clipping_percentage, 4),
            'dynamic_range': round(dynamic_range, 2),
            'headroom': round(headroom, 2)
        }

    except (OSError, ValueError, RuntimeError) as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None


def detect_noise_types(file_path: str) -> Optional[Dict[str, Union[bool, float]]]:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã«å«ã¾ã‚Œã‚‹ãƒã‚¤ã‚ºã®ç¨®é¡ã‚’æ¤œå‡ºã™ã‚‹

    Args:
        file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        ãƒã‚¤ã‚ºæ¤œå‡ºçµæœã®è¾æ›¸
        {
            'white_noise_level': ãƒ›ãƒ¯ã‚¤ãƒˆãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«(dB),
            'has_white_noise': ãƒ›ãƒ¯ã‚¤ãƒˆãƒã‚¤ã‚ºæœ‰ç„¡,
            'hum_60hz_level': 60Hzãƒãƒ ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«(dB),
            'hum_50hz_level': 50Hzãƒãƒ ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«(dB),
            'has_hum_noise': ãƒãƒ ãƒã‚¤ã‚ºæœ‰ç„¡,
            'click_count': ã‚¯ãƒªãƒƒã‚¯ãƒ»ãƒãƒƒãƒ—ãƒã‚¤ã‚ºæ•°,
            'has_click_noise': ã‚¯ãƒªãƒƒã‚¯ãƒ»ãƒãƒƒãƒ—ãƒã‚¤ã‚ºæœ‰ç„¡,
            'background_noise_level': èƒŒæ™¯ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«(dB),
            'has_background_noise': èƒŒæ™¯ãƒã‚¤ã‚ºæœ‰ç„¡
        }
    """
    try:
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        y, sr = librosa.load(file_path, sr=None, mono=True)

        # 1. ãƒ›ãƒ¯ã‚¤ãƒˆãƒã‚¤ã‚ºæ¤œå‡º
        # æœ€åˆã®0.5ç§’ã‚’ãƒã‚¤ã‚ºåŒºé–“ã¨ã—ã¦åˆ†æ
        noise_samples = int(0.5 * sr)
        noise_segment = y[:noise_samples]
        white_noise_level = 20 * np.log10(np.std(noise_segment)) if np.std(noise_segment) > 0 else -np.inf
        has_white_noise = white_noise_level > -60.0  # -60dBä»¥ä¸Šã‚’ãƒã‚¤ã‚ºã‚ã‚Šã¨åˆ¤å®š

        # 2. ãƒãƒ ãƒã‚¤ã‚ºæ¤œå‡ºï¼ˆ50Hz/60Hzï¼‰
        # FFTã§ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æ
        fft = np.fft.rfft(y)
        freqs = np.fft.rfftfreq(len(y), 1/sr)
        magnitude_db = 20 * np.log10(np.abs(fft) + 1e-10)

        # 60Hzä»˜è¿‘ã®ãƒ”ãƒ¼ã‚¯ã‚’æ¤œå‡º
        idx_60hz = np.argmin(np.abs(freqs - 60))
        hum_60hz_level = float(magnitude_db[idx_60hz])

        # 50Hzä»˜è¿‘ã®ãƒ”ãƒ¼ã‚¯ã‚’æ¤œå‡º
        idx_50hz = np.argmin(np.abs(freqs - 50))
        hum_50hz_level = float(magnitude_db[idx_50hz])

        # å‘¨å›²ã®å¹³å‡ã¨æ¯”è¼ƒ
        window = 10
        avg_around_60 = np.mean(magnitude_db[max(0, int(idx_60hz)-window):int(idx_60hz)+window])
        avg_around_50 = np.mean(magnitude_db[max(0, int(idx_50hz)-window):int(idx_50hz)+window])

        has_hum_noise = bool((hum_60hz_level - avg_around_60 > 20) or (hum_50hz_level - avg_around_50 > 20))

        # 3. ã‚¯ãƒªãƒƒã‚¯ãƒ»ãƒãƒƒãƒ—ãƒã‚¤ã‚ºæ¤œå‡º
        # å¾®åˆ†ã®æ€¥æ¿€ãªå¤‰åŒ–ã‚’æ¤œå‡º
        diff = np.diff(y, prepend=y[0])
        std_diff = np.std(diff)
        clicks = np.abs(diff) > (3.0 * std_diff)
        click_count = int(np.sum(clicks))
        has_click_noise = click_count > 10  # 10å€‹ä»¥ä¸Šã‚’ãƒã‚¤ã‚ºã‚ã‚Šã¨åˆ¤å®š

        # 4. èƒŒæ™¯ãƒã‚¤ã‚ºæ¤œå‡º
        # éŸ³å£°ã®ãªã„åŒºé–“ï¼ˆä½æŒ¯å¹…åŒºé–“ï¼‰ã®ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã‚’æ¸¬å®š
        rms_per_frame = librosa.feature.rms(y=y, frame_length=2048, hop_length=512)[0]
        threshold = np.percentile(rms_per_frame, 10)  # ä¸‹ä½10%ã‚’ç„¡éŸ³åŒºé–“ã¨ã™ã‚‹
        silent_frames = rms_per_frame < threshold

        if np.sum(silent_frames) > 0:
            background_noise_level = 20 * np.log10(np.mean(rms_per_frame[silent_frames]))
        else:
            background_noise_level = -np.inf

        has_background_noise = background_noise_level > -50.0  # -50dBä»¥ä¸Šã‚’èƒŒæ™¯ãƒã‚¤ã‚ºã‚ã‚Šã¨åˆ¤å®š

        return {
            'white_noise_level': round(white_noise_level, 2),
            'has_white_noise': has_white_noise,
            'hum_60hz_level': round(hum_60hz_level, 2),
            'hum_50hz_level': round(hum_50hz_level, 2),
            'has_hum_noise': has_hum_noise,
            'click_count': click_count,
            'has_click_noise': has_click_noise,
            'background_noise_level': round(background_noise_level, 2),
            'has_background_noise': has_background_noise
        }

    except (OSError, ValueError, RuntimeError) as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None


def print_noise_detection(info: Dict[str, Union[bool, float]], filename: str) -> None:
    """
    ãƒã‚¤ã‚ºæ¤œå‡ºçµæœã‚’æ•´å½¢ã—ã¦å‡ºåŠ›ã™ã‚‹

    Args:
        info: ãƒã‚¤ã‚ºæ¤œå‡ºæƒ…å ±ã®è¾æ›¸
        filename: ãƒ•ã‚¡ã‚¤ãƒ«å
    """
    print("\n" + "=" * 70)
    print(f"ã€ãƒã‚¤ã‚ºæ¤œå‡ºåˆ†æã€‘: {filename}")
    print("=" * 70)

    # ãƒ›ãƒ¯ã‚¤ãƒˆãƒã‚¤ã‚º
    status = "ğŸ”´ æ¤œå‡º" if info['has_white_noise'] else "âœ… ãªã—"
    print(f"ãƒ›ãƒ¯ã‚¤ãƒˆãƒã‚¤ã‚º    : {status}")
    print(f"  ãƒ¬ãƒ™ãƒ«: {info['white_noise_level']:+.2f} dB")
    if info['has_white_noise']:
        print("  â†’ ã‚¹ãƒšã‚¯ãƒˆãƒ«æ¸›ç®—æ³•ã«ã‚ˆã‚‹é™¤å»ã‚’æ¨å¥¨")

    print("-" * 70)

    # ãƒãƒ ãƒã‚¤ã‚º
    status = "ğŸ”´ æ¤œå‡º" if info['has_hum_noise'] else "âœ… ãªã—"
    print(f"ãƒãƒ ãƒã‚¤ã‚º        : {status}")
    print(f"  60Hz: {info['hum_60hz_level']:+.2f} dB")
    print(f"  50Hz: {info['hum_50hz_level']:+.2f} dB")
    if info['has_hum_noise']:
        print("  â†’ ãƒãƒƒãƒãƒ•ã‚£ãƒ«ã‚¿ã«ã‚ˆã‚‹é™¤å»ã‚’æ¨å¥¨")

    print("-" * 70)

    # ã‚¯ãƒªãƒƒã‚¯ãƒ»ãƒãƒƒãƒ—ãƒã‚¤ã‚º
    status = "ğŸ”´ æ¤œå‡º" if info['has_click_noise'] else "âœ… ãªã—"
    print(f"ã‚¯ãƒªãƒƒã‚¯/ãƒãƒƒãƒ—  : {status}")
    print(f"  æ¤œå‡ºæ•°: {info['click_count']}å€‹")
    if info['has_click_noise']:
        print("  â†’ ãƒ‡ã‚¯ãƒªãƒƒã‚¯å‡¦ç†ã‚’æ¨å¥¨")

    print("-" * 70)

    # èƒŒæ™¯ãƒã‚¤ã‚º
    status = "ğŸ”´ æ¤œå‡º" if info['has_background_noise'] else "âœ… ãªã—"
    print(f"èƒŒæ™¯ãƒã‚¤ã‚º        : {status}")
    print(f"  ãƒ¬ãƒ™ãƒ«: {info['background_noise_level']:+.2f} dB")
    if info['has_background_noise']:
        print("  â†’ è»½ã‚ã®ãƒã‚¤ã‚ºæŠ‘åˆ¶ã‚’æ¨å¥¨ï¼ˆå¼·ã™ãã‚‹ã¨ãƒ­ãƒœå£°ã«ãªã‚‹ã®ã§æ³¨æ„ï¼‰")

    print("=" * 70 + "\n")


def analyze_frequency_characteristics(file_path: str) -> Optional[Dict[str, Union[float, bool]]]:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‘¨æ³¢æ•°ç‰¹æ€§ã‚’åˆ†æã™ã‚‹

    Args:
        file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        å‘¨æ³¢æ•°ç‰¹æ€§åˆ†æçµæœã®è¾æ›¸
        {
            'low_freq_energy': ä½åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼(80Hzä»¥ä¸‹) dB,
            'needs_highpass': ãƒã‚¤ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿å¿…è¦æ€§,
            'voice_band_energy': éŸ³å£°å¸¯åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼(300-4000Hz) dB,
            'high_freq_energy': é«˜åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼(8kHzä»¥ä¸Š) dB,
            'needs_lowpass': ãƒ­ãƒ¼ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿å¿…è¦æ€§,
            'sibilance_level': ã‚·ãƒ“ãƒ©ãƒ³ã‚¹(6-10kHz)ãƒ¬ãƒ™ãƒ« dB,
            'needs_deesser': ãƒ‡ã‚£ã‚¨ãƒƒã‚µãƒ¼å¿…è¦æ€§,
            'spectral_centroid': ã‚¹ãƒšã‚¯ãƒˆãƒ«é‡å¿ƒ Hz,
            'voice_clarity': éŸ³å£°æ˜ç­åº¦ (0-1),
            'needs_eq_boost': éŸ³å£°å¸¯åŸŸãƒ–ãƒ¼ã‚¹ãƒˆå¿…è¦æ€§
        }
    """
    try:
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        y, sr = librosa.load(file_path, sr=None, mono=True)

        # STFTã§ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æ
        stft = librosa.stft(y, n_fft=2048, hop_length=512)
        magnitude = np.abs(stft)
        freqs = librosa.fft_frequencies(sr=sr, n_fft=2048)

        # å‘¨æ³¢æ•°ãƒ“ãƒ³ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
        def get_freq_range(f_min, f_max):
            idx_min = np.argmin(np.abs(freqs - f_min))
            idx_max = np.argmin(np.abs(freqs - f_max))
            return idx_min, idx_max

        # 1. ä½åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆ80Hzä»¥ä¸‹ï¼‰
        idx_low_start, idx_low_end = get_freq_range(0, 80)
        low_freq_magnitude = magnitude[idx_low_start:idx_low_end, :]
        low_freq_energy = 20 * np.log10(np.mean(low_freq_magnitude) + 1e-10)

        # 2. éŸ³å£°å¸¯åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆ300-4000Hzï¼‰
        idx_voice_start, idx_voice_end = get_freq_range(300, 4000)
        voice_band_magnitude = magnitude[idx_voice_start:idx_voice_end, :]
        voice_band_energy = 20 * np.log10(np.mean(voice_band_magnitude) + 1e-10)

        # 3. é«˜åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆ8kHzä»¥ä¸Šï¼‰
        idx_high_start, idx_high_end = get_freq_range(8000, sr/2)
        high_freq_magnitude = magnitude[idx_high_start:idx_high_end, :]
        high_freq_energy = 20 * np.log10(np.mean(high_freq_magnitude) + 1e-10)

        # 4. ã‚·ãƒ“ãƒ©ãƒ³ã‚¹å¸¯åŸŸï¼ˆ6-10kHzï¼‰- ã‚µè¡Œã®éŸ³
        if sr >= 20000:  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãŒååˆ†é«˜ã„å ´åˆ
            idx_sib_start, idx_sib_end = get_freq_range(6000, 10000)
            sibilance_magnitude = magnitude[idx_sib_start:idx_sib_end, :]
            sibilance_level = 20 * np.log10(np.mean(sibilance_magnitude) + 1e-10)
        else:
            sibilance_level = -np.inf

        # 5. ã‚¹ãƒšã‚¯ãƒˆãƒ«é‡å¿ƒï¼ˆéŸ³è‰²ã®æ˜ã‚‹ã•æŒ‡æ¨™ï¼‰
        spectral_centroid = float(np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)))

        # 6. éŸ³å£°æ˜ç­åº¦ï¼ˆéŸ³å£°å¸¯åŸŸ vs å…¨ä½“ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¯”ï¼‰
        total_magnitude = magnitude
        total_energy = np.mean(total_magnitude)
        voice_energy = np.mean(voice_band_magnitude)
        voice_clarity = float(voice_energy / (total_energy + 1e-10))

        # åˆ¤å®šåŸºæº–
        needs_highpass = low_freq_energy > -40.0  # ä½åŸŸãŒ-40dBä»¥ä¸Šãªã‚‰é™¤å»æ¨å¥¨
        needs_lowpass = high_freq_energy > -35.0 and high_freq_energy > (voice_band_energy - 10)  # é«˜åŸŸãƒã‚¤ã‚ºåˆ¤å®š
        needs_deesser = sibilance_level > -30.0 and sibilance_level > (voice_band_energy - 5)  # ã‚·ãƒ“ãƒ©ãƒ³ã‚¹å¼·ã„
        needs_eq_boost = voice_clarity < 0.3  # éŸ³å£°å¸¯åŸŸãŒå¼±ã„

        return {
            'low_freq_energy': round(low_freq_energy, 2),
            'needs_highpass': needs_highpass,
            'voice_band_energy': round(voice_band_energy, 2),
            'high_freq_energy': round(high_freq_energy, 2),
            'needs_lowpass': needs_lowpass,
            'sibilance_level': round(sibilance_level, 2),
            'needs_deesser': needs_deesser,
            'spectral_centroid': round(spectral_centroid, 2),
            'voice_clarity': round(voice_clarity, 3),
            'needs_eq_boost': needs_eq_boost
        }

    except (OSError, ValueError, RuntimeError) as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None


def print_frequency_analysis(info: Dict[str, Union[float, bool]], filename: str) -> None:
    """
    å‘¨æ³¢æ•°ç‰¹æ€§åˆ†æçµæœã‚’æ•´å½¢ã—ã¦å‡ºåŠ›ã™ã‚‹

    Args:
        info: å‘¨æ³¢æ•°ç‰¹æ€§æƒ…å ±ã®è¾æ›¸
        filename: ãƒ•ã‚¡ã‚¤ãƒ«å
    """
    print("\n" + "=" * 70)
    print(f"ã€å‘¨æ³¢æ•°ç‰¹æ€§åˆ†æã€‘: {filename}")
    print("=" * 70)

    # ä½åŸŸï¼ˆãƒã‚¤ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿åˆ¤å®šï¼‰
    status = "ğŸ”´ è¦å‡¦ç†" if info['needs_highpass'] else "âœ… é©åˆ‡"
    print(f"ä½åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼ (ã€œ80Hz)  : {status}")
    print(f"  ãƒ¬ãƒ™ãƒ«: {info['low_freq_energy']:+.2f} dB")
    if info['needs_highpass']:
        print("  â†’ ãƒã‚¤ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿æ¨å¥¨ï¼ˆ80ã€œ120Hzä»¥ä¸‹ã‚«ãƒƒãƒˆï¼‰")
        print("     ä½ã„å”¸ã‚Šãƒ»æŒ¯å‹•ãƒ»é¢¨éŸ³ã‚’é™¤å»")

    print("-" * 70)

    # éŸ³å£°å¸¯åŸŸ
    status = "ğŸ”´ å¼±ã„" if info['needs_eq_boost'] else "âœ… è‰¯å¥½"
    print(f"éŸ³å£°å¸¯åŸŸ (300-4000Hz)    : {status}")
    print(f"  ãƒ¬ãƒ™ãƒ«: {info['voice_band_energy']:+.2f} dB")
    print(f"  æ˜ç­åº¦: {info['voice_clarity']:.3f}")
    if info['needs_eq_boost']:
        print("  â†’ éŸ³å£°å¸¯åŸŸã®ãƒ–ãƒ¼ã‚¹ãƒˆæ¨å¥¨")
        print("     300Hzã€œ4kHzã‚’+2ã€œ3dBç¨‹åº¦æŒã¡ä¸Šã’")

    print("-" * 70)

    # é«˜åŸŸï¼ˆãƒ­ãƒ¼ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿åˆ¤å®šï¼‰
    status = "ğŸ”´ è¦å‡¦ç†" if info['needs_lowpass'] else "âœ… é©åˆ‡"
    print(f"é«˜åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼ (8kHzã€œ)  : {status}")
    print(f"  ãƒ¬ãƒ™ãƒ«: {info['high_freq_energy']:+.2f} dB")
    if info['needs_lowpass']:
        print("  â†’ ãƒ­ãƒ¼ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿æ¨å¥¨ï¼ˆ16kHzä»˜è¿‘ã§ã‚«ãƒƒãƒˆï¼‰")
        print("     é«˜åŸŸãƒã‚¤ã‚ºã‚’é™¤å»")

    print("-" * 70)

    # ã‚·ãƒ“ãƒ©ãƒ³ã‚¹ï¼ˆãƒ‡ã‚£ã‚¨ãƒƒã‚µãƒ¼åˆ¤å®šï¼‰
    status = "ğŸ”´ å¼·ã„" if info['needs_deesser'] else "âœ… é©åˆ‡"
    print(f"ã‚·ãƒ“ãƒ©ãƒ³ã‚¹ (6-10kHz)     : {status}")
    print(f"  ãƒ¬ãƒ™ãƒ«: {info['sibilance_level']:+.2f} dB")
    if info['needs_deesser']:
        print("  â†’ ãƒ‡ã‚£ã‚¨ãƒƒã‚µãƒ¼æ¨å¥¨")
        print("     ã‚µè¡Œã®åˆºã•ã‚‹éŸ³ï¼ˆã‚·ãƒ“ãƒ©ãƒ³ã‚¹ï¼‰ã‚’æŠ‘åˆ¶")

    print("-" * 70)

    # ã‚¹ãƒšã‚¯ãƒˆãƒ«é‡å¿ƒ
    print(f"ã‚¹ãƒšã‚¯ãƒˆãƒ«é‡å¿ƒ           : {info['spectral_centroid']:.2f} Hz")
    if info['spectral_centroid'] < 1000:
        print("  éŸ³è‰²ãŒæš—ã‚ãƒ»ã“ã‚‚ã‚Šæ°—å‘³")
    elif info['spectral_centroid'] > 3000:
        print("  éŸ³è‰²ãŒæ˜ã‚‹ã‚ãƒ»ã‚·ãƒ£ãƒ¼ãƒ—")
    else:
        print("  éŸ³è‰²ãƒãƒ©ãƒ³ã‚¹è‰¯å¥½")

    print("=" * 70 + "\n")


def analyze_silence_and_voice(file_path: str, silence_thresh_db: float = -40.0) -> Optional[Dict[str, Union[float, int, List[tuple]]]]:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç„¡éŸ³åŒºé–“ã¨éŸ³å£°åŒºé–“ã‚’åˆ†æã™ã‚‹

    Args:
        file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        silence_thresh_db: ç„¡éŸ³åˆ¤å®šã®é–¾å€¤ï¼ˆdBFSï¼‰

    Returns:
        ç„¡éŸ³ãƒ»éŸ³å£°åŒºé–“åˆ†æçµæœã®è¾æ›¸
        {
            'total_duration': ç·å†ç”Ÿæ™‚é–“(ç§’),
            'silence_duration': ç„¡éŸ³åŒºé–“ã®åˆè¨ˆæ™‚é–“(ç§’),
            'voice_duration': éŸ³å£°åŒºé–“ã®åˆè¨ˆæ™‚é–“(ç§’),
            'silence_ratio': ç„¡éŸ³åŒºé–“ã®å‰²åˆ(0-1),
            'silence_segments': ç„¡éŸ³åŒºé–“ã®ãƒªã‚¹ãƒˆ[(é–‹å§‹æ™‚åˆ», çµ‚äº†æ™‚åˆ»), ...],
            'voice_segments': éŸ³å£°åŒºé–“ã®ãƒªã‚¹ãƒˆ[(é–‹å§‹æ™‚åˆ», çµ‚äº†æ™‚åˆ»), ...],
            'leading_silence': å…ˆé ­ã®ç„¡éŸ³æ™‚é–“(ç§’),
            'trailing_silence': æœ«å°¾ã®ç„¡éŸ³æ™‚é–“(ç§’),
            'longest_silence': æœ€é•·ç„¡éŸ³åŒºé–“(ç§’),
            'voice_segment_count': éŸ³å£°åŒºé–“ã®æ•°,
            'needs_trim': å…ˆé ­ãƒ»æœ«å°¾ã®ãƒˆãƒªãƒŸãƒ³ã‚°å¿…è¦æ€§,
            'needs_compression': é•·ã„ç„¡éŸ³åœ§ç¸®å¿…è¦æ€§,
            'needs_vad_split': VADåˆ†å‰²å¿…è¦æ€§
        }
    """
    try:
        # éŸ³å£°ã‚’èª­ã¿è¾¼ã¿
        y, sr = librosa.load(file_path, sr=None, mono=True)
        total_duration = len(y) / sr

        # RMSã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’è¨ˆç®—ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ï¼‰
        frame_length = 2048
        hop_length = 512
        rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]

        # dBFSã«å¤‰æ›
        rms_db = librosa.amplitude_to_db(rms, ref=np.max)

        # ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ™‚åˆ»ã‚’è¨ˆç®—
        frames = range(len(rms_db))
        times = librosa.frames_to_time(frames, sr=sr, hop_length=hop_length)

        # ç„¡éŸ³åˆ¤å®š
        is_silence = rms_db < silence_thresh_db

        # åŒºé–“ã‚’æ¤œå‡ºï¼ˆé€£ç¶šã™ã‚‹ç„¡éŸ³/éŸ³å£°ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼‰
        silence_segments = []
        voice_segments = []

        i = 0
        while i < len(is_silence):
            if is_silence[i]:
                # ç„¡éŸ³åŒºé–“ã®é–‹å§‹
                start = times[i]
                while i < len(is_silence) and is_silence[i]:
                    i += 1
                end = times[i-1] if i < len(times) else total_duration
                silence_segments.append((float(start), float(end)))
            else:
                # éŸ³å£°åŒºé–“ã®é–‹å§‹
                start = times[i]
                while i < len(is_silence) and not is_silence[i]:
                    i += 1
                end = times[i-1] if i < len(times) else total_duration
                voice_segments.append((float(start), float(end)))

        # çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
        silence_duration = sum(end - start for start, end in silence_segments)
        voice_duration = sum(end - start for start, end in voice_segments)
        silence_ratio = silence_duration / total_duration if total_duration > 0 else 0

        # å…ˆé ­ã¨æœ«å°¾ã®ç„¡éŸ³
        leading_silence = silence_segments[0][1] - silence_segments[0][0] if silence_segments and silence_segments[0][0] < 0.1 else 0.0
        trailing_silence = silence_segments[-1][1] - silence_segments[-1][0] if silence_segments and silence_segments[-1][1] > (total_duration - 0.1) else 0.0

        # æœ€é•·ç„¡éŸ³åŒºé–“
        longest_silence = max((end - start for start, end in silence_segments), default=0.0)

        # éŸ³å£°åŒºé–“ã®æ•°
        voice_segment_count = len(voice_segments)

        # å‡¦ç†ã®å¿…è¦æ€§åˆ¤å®š
        needs_trim = leading_silence > 0.5 or trailing_silence > 0.5  # 0.5ç§’ä»¥ä¸Šã®ç„¡éŸ³
        needs_compression = longest_silence > 1.0  # 1ç§’ä»¥ä¸Šã®ç„¡éŸ³ãŒã‚ã‚‹
        needs_vad_split = voice_segment_count > 5 and total_duration > 30  # é•·ã„ãƒ•ã‚¡ã‚¤ãƒ«ã§è¤‡æ•°ã®éŸ³å£°åŒºé–“

        return {
            'total_duration': round(total_duration, 2),
            'silence_duration': round(silence_duration, 2),
            'voice_duration': round(voice_duration, 2),
            'silence_ratio': round(silence_ratio, 3),
            'silence_segments': silence_segments,
            'voice_segments': voice_segments,
            'leading_silence': round(leading_silence, 2),
            'trailing_silence': round(trailing_silence, 2),
            'longest_silence': round(longest_silence, 2),
            'voice_segment_count': voice_segment_count,
            'needs_trim': needs_trim,
            'needs_compression': needs_compression,
            'needs_vad_split': needs_vad_split
        }

    except (OSError, ValueError, RuntimeError) as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None


def print_silence_analysis(info: Dict[str, Union[float, int, List[tuple]]], filename: str) -> None:
    """
    ç„¡éŸ³ãƒ»éŸ³å£°åŒºé–“åˆ†æçµæœã‚’æ•´å½¢ã—ã¦å‡ºåŠ›ã™ã‚‹

    Args:
        info: ç„¡éŸ³ãƒ»éŸ³å£°åŒºé–“æƒ…å ±ã®è¾æ›¸
        filename: ãƒ•ã‚¡ã‚¤ãƒ«å
    """
    print("\n" + "=" * 70)
    print(f"ã€ç„¡éŸ³ãƒ»éŸ³å£°åŒºé–“åˆ†æã€‘: {filename}")
    print("=" * 70)

    # åŸºæœ¬çµ±è¨ˆ
    print(f"ç·å†ç”Ÿæ™‚é–“          : {info['total_duration']:.2f} ç§’")
    silence_ratio = float(info['silence_ratio']) if isinstance(info['silence_ratio'], (int, float)) else 0.0
    print(f"éŸ³å£°åŒºé–“            : {info['voice_duration']:.2f} ç§’ ({(1-silence_ratio)*100:.1f}%)")
    print(f"ç„¡éŸ³åŒºé–“            : {info['silence_duration']:.2f} ç§’ ({silence_ratio*100:.1f}%)")

    print("-" * 70)

    # å…ˆé ­ãƒ»æœ«å°¾ã®ç„¡éŸ³
    status = "ğŸ”´ è¦å‡¦ç†" if info['needs_trim'] else "âœ… é©åˆ‡"
    print(f"å…ˆé ­ãƒ»æœ«å°¾ã®ç„¡éŸ³    : {status}")
    print(f"  å…ˆé ­: {info['leading_silence']:.2f} ç§’")
    print(f"  æœ«å°¾: {info['trailing_silence']:.2f} ç§’")
    if info['needs_trim']:
        print("  â†’ å…ˆé ­ãƒ»æœ«å°¾ã®ãƒˆãƒªãƒŸãƒ³ã‚°æ¨å¥¨")

    print("-" * 70)

    # é•·ã„ç„¡éŸ³åŒºé–“
    status = "ğŸ”´ è¦å‡¦ç†" if info['needs_compression'] else "âœ… é©åˆ‡"
    print(f"æœ€é•·ç„¡éŸ³åŒºé–“        : {status}")
    print(f"  é•·ã•: {info['longest_silence']:.2f} ç§’")
    if info['needs_compression']:
        print("  â†’ é•·ã„ç„¡éŸ³ã®åœ§ç¸®æ¨å¥¨ï¼ˆä¾‹: 1.0ç§’ä»¥ä¸Šâ†’0.5ç§’ã«çŸ­ç¸®ï¼‰")

    print("-" * 70)

    # VADåˆ†å‰²
    status = "ğŸ”´ æ¨å¥¨" if info['needs_vad_split'] else "âœ… ä¸è¦"
    print(f"VADåˆ†å‰²             : {status}")
    print(f"  éŸ³å£°åŒºé–“æ•°: {info['voice_segment_count']}å€‹")
    if info['needs_vad_split']:
        print("  â†’ VADã«ã‚ˆã‚‹éŸ³å£°åŒºé–“ã”ã¨ã®åˆ†å‰²ã‚’æ¨å¥¨")
        print("     ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦åŠ¹ç‡çš„")

    print("-" * 70)

    # éŸ³å£°åŒºé–“ã®è©³ç´°ï¼ˆæœ€åˆã®5å€‹ã¾ã§ï¼‰
    print("éŸ³å£°åŒºé–“ã®è©³ç´° (æœ€åˆã®5å€‹):")
    voice_segments = info.get('voice_segments', [])
    if isinstance(voice_segments, list):
        for i, (start, end) in enumerate(voice_segments[:5], 1):
            duration = end - start
            print(f"  {i}. {start:.2f}s - {end:.2f}s (é•·ã•: {duration:.2f}s)")

        if len(voice_segments) > 5:
            print(f"  ... ä»– {len(voice_segments) - 5}å€‹ã®éŸ³å£°åŒºé–“")

    print("=" * 70 + "\n")


def print_level_analysis(info: Dict[str, float], filename: str) -> None:
    """
    ãƒ¬ãƒ™ãƒ«åˆ†æçµæœã‚’æ•´å½¢ã—ã¦å‡ºåŠ›ã™ã‚‹

    Args:
        info: ãƒ¬ãƒ™ãƒ«æƒ…å ±ã®è¾æ›¸
        filename: ãƒ•ã‚¡ã‚¤ãƒ«å
    """
    print("\n" + "=" * 70)
    print(f"ã€éŸ³é‡ãƒ»ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°åˆ†æã€‘: {filename}")
    print("=" * 70)
    print(f"ãƒ”ãƒ¼ã‚¯ãƒ¬ãƒ™ãƒ«      : {info['peak_db']:+.2f} dBFS")
    print(f"RMSãƒ¬ãƒ™ãƒ«         : {info['rms_db']:+.2f} dBFS")
    print(f"ãƒ©ã‚¦ãƒ‰ãƒã‚¹(æ¨å®š)  : {info['lufs']:+.2f} LUFS")
    print(f"ã‚¯ãƒ¬ã‚¹ãƒˆãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼: {info['crest_factor']:+.2f} dB")
    print(f"ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãƒ¬ãƒ³ã‚¸: {info['dynamic_range']:+.2f} dB")
    print(f"ãƒ˜ãƒƒãƒ‰ãƒ«ãƒ¼ãƒ       : {info['headroom']:+.2f} dB")
    print("-" * 70)
    print(f"ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°      : {info['clipping_samples']}ã‚µãƒ³ãƒ—ãƒ« ({info['clipping_percentage']:.4f}%)")

    # æ¨å¥¨äº‹é …ã‚’è¡¨ç¤º
    print("-" * 70)
    print("ã€æ¨å¥¨äº‹é …ã€‘")

    # ãƒ”ãƒ¼ã‚¯ãƒ¬ãƒ™ãƒ«ã®ãƒã‚§ãƒƒã‚¯
    if info['peak_db'] > -1.0:
        print("âš ï¸  ãƒ”ãƒ¼ã‚¯ãŒé«˜ã™ãã¾ã™ï¼ˆ-1dBFSä»¥ä¸Šï¼‰â†’ ãƒ”ãƒ¼ã‚¯ãƒãƒ¼ãƒãƒ©ã‚¤ã‚ºæ¨å¥¨ï¼ˆ-1ã€œ-3dBFSï¼‰")
    elif info['peak_db'] < -10.0:
        print("âš ï¸  ãƒ”ãƒ¼ã‚¯ãŒä½ã™ãã¾ã™ï¼ˆ-10dBFSä»¥ä¸‹ï¼‰â†’ ã‚²ã‚¤ãƒ³ã‚¢ãƒƒãƒ—æ¨å¥¨")
    else:
        print("âœ… ãƒ”ãƒ¼ã‚¯ãƒ¬ãƒ™ãƒ«ã¯é©åˆ‡ã§ã™")

    # ãƒ©ã‚¦ãƒ‰ãƒã‚¹ã®ãƒã‚§ãƒƒã‚¯
    if info['lufs'] > -16.0:
        print("âš ï¸  ãƒ©ã‚¦ãƒ‰ãƒã‚¹ãŒé«˜ã™ãã¾ã™ â†’ ãƒ©ã‚¦ãƒ‰ãƒã‚¹ãƒãƒ¼ãƒãƒ©ã‚¤ã‚ºæ¨å¥¨ï¼ˆ-20ã€œ-16 LUFSï¼‰")
    elif info['lufs'] < -30.0:
        print("âš ï¸  ãƒ©ã‚¦ãƒ‰ãƒã‚¹ãŒä½ã™ãã¾ã™ â†’ ãƒ©ã‚¦ãƒ‰ãƒã‚¹ãƒãƒ¼ãƒãƒ©ã‚¤ã‚ºæ¨å¥¨")
    else:
        print("âœ… ãƒ©ã‚¦ãƒ‰ãƒã‚¹ã¯é©åˆ‡ã§ã™")

    # ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã®ãƒã‚§ãƒƒã‚¯
    if info['clipping_percentage'] > 0.01:
        print(f"ğŸ”´ ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°æ¤œå‡ºï¼ ({info['clipping_percentage']:.4f}%) â†’ ãƒ‡ã‚¯ãƒªãƒƒãƒ—å‡¦ç†æ¨å¥¨")
    elif info['clipping_percentage'] > 0:
        print(f"âš ï¸  ã‚ãšã‹ãªã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã‚ã‚Š ({info['clipping_percentage']:.4f}%)")
    else:
        print("âœ… ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ãªã—")

    # ãƒ˜ãƒƒãƒ‰ãƒ«ãƒ¼ãƒ ã®ãƒã‚§ãƒƒã‚¯
    if info['headroom'] < 1.0:
        print("âš ï¸  ãƒ˜ãƒƒãƒ‰ãƒ«ãƒ¼ãƒ ãŒä¸è¶³ â†’ ãƒ”ãƒ¼ã‚¯ã‚’ä¸‹ã’ã‚‹ã“ã¨ã‚’æ¨å¥¨")

    print("=" * 70 + "\n")


def print_audio_info(info: Dict[str, Union[str, int, float]]) -> None:
    """
    éŸ³å£°æƒ…å ±ã‚’æ•´å½¢ã—ã¦å‡ºåŠ›ã™ã‚‹

    Args:
        info: éŸ³å£°æƒ…å ±ã®è¾æ›¸
    """
    print("\n" + "=" * 70)
    print("ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã€‘")
    print("=" * 70)
    print(f"ãƒ•ã‚¡ã‚¤ãƒ«å        : {info['filename']}")
    print(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º    : {info['file_size_mb']} MB")
    print(f"å½¢å¼              : {info['format']}")
    print("-" * 60)
    print(f"é•·ã•              : {info['duration']} ç§’")
    print(f"ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ: {info['sample_rate']} Hz")
    print(f"ãƒãƒ£ãƒ³ãƒãƒ«        : {info['channel_type']} ({info['channels']}ch)")
    print(f"ãƒ“ãƒƒãƒˆæ·±åº¦        : {info['bit_depth']} bit")
    print(f"ç·ã‚µãƒ³ãƒ—ãƒ«æ•°      : {info['total_samples']:,}")
    print("-" * 60)
    print(f"ãƒ”ãƒ¼ã‚¯æŒ¯å¹…        : {info['peak_amplitude']}")
    print(f"RMSãƒ¬ãƒ™ãƒ«         : {info['rms_level']} dB")
    print("=" * 60 + "\n")


def analyze_directory(directory: str, extensions: Optional[List[str]] = None) -> List[Dict]:
    """
    ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã™ã¹ã¦ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã™ã‚‹

    Args:
        directory: å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        extensions: å¯¾è±¡ã¨ã™ã‚‹æ‹¡å¼µå­ãƒªã‚¹ãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ['.wav', '.mp3', '.m4a', '.flac', '.ogg']ï¼‰

    Returns:
        åˆ†æçµæœã®ãƒªã‚¹ãƒˆ
    """
    if extensions is None:
        extensions = ['.wav', '.mp3', '.m4a', '.flac', '.ogg', '.aac']

    results: List[Dict[str, Union[str, int, float]]] = []
    dir_path = Path(directory)

    if not dir_path.exists():
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - {directory}")
        return results

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    audio_files: List[Path] = []
    for ext in extensions:
        audio_files.extend(dir_path.glob(f"*{ext}"))

    print(f"\n{len(audio_files)}å€‹ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\n")

    for audio_file in sorted(audio_files):
        print(f"åˆ†æä¸­: {audio_file.name}...")
        info = analyze_audio_file(str(audio_file))
        if info:
            results.append(info)
            print_audio_info(info)

    return results


def generate_summary_report(results: List[Dict], output_file: str = "audio_analysis_report.txt") -> None:
    """
    åˆ†æçµæœã®ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹

    Args:
        results: åˆ†æçµæœã®ãƒªã‚¹ãƒˆ
        output_file: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
    """
    if not results:
        print("åˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“")
        return

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n")
        f.write("=" * 80 + "\n\n")

        f.write(f"åˆ†æãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(results)}\n\n")

        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°
        for i, info in enumerate(results, 1):
            f.write(f"\n--- ãƒ•ã‚¡ã‚¤ãƒ« {i} ---\n")
            f.write(f"ãƒ•ã‚¡ã‚¤ãƒ«å        : {info['filename']}\n")
            f.write(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º    : {info['file_size_mb']} MB\n")
            f.write(f"å½¢å¼              : {info['format']}\n")
            f.write(f"é•·ã•              : {info['duration']} ç§’\n")
            f.write(f"ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ: {info['sample_rate']} Hz\n")
            f.write(f"ãƒãƒ£ãƒ³ãƒãƒ«        : {info['channel_type']}\n")
            f.write(f"ãƒ“ãƒƒãƒˆæ·±åº¦        : {info['bit_depth']} bit\n")
            f.write(f"ç·ã‚µãƒ³ãƒ—ãƒ«æ•°      : {info['total_samples']:,}\n")
            f.write(f"ãƒ”ãƒ¼ã‚¯æŒ¯å¹…        : {info['peak_amplitude']}\n")
            f.write(f"RMSãƒ¬ãƒ™ãƒ«         : {info['rms_level']} dB\n")

        # ã‚µãƒãƒªãƒ¼çµ±è¨ˆ
        f.write("\n" + "=" * 80 + "\n")
        f.write("ã‚µãƒãƒªãƒ¼çµ±è¨ˆ\n")
        f.write("=" * 80 + "\n")

        total_duration = sum(r['duration'] for r in results)
        total_size = sum(r['file_size_mb'] for r in results)
        sample_rates = [r['sample_rate'] for r in results]
        channels = [r['channels'] for r in results]

        f.write(f"ç·å†ç”Ÿæ™‚é–“        : {total_duration:.2f} ç§’ ({total_duration/60:.2f} åˆ†)\n")
        f.write(f"ç·ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º  : {total_size:.2f} MB\n")
        f.write(f"ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ: {set(sample_rates)}\n")
        f.write(f"ãƒãƒ£ãƒ³ãƒãƒ«æ•°      : {set(channels)}\n")

    print(f"\nãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æä¾‹
    print("=" * 60)
    print("ã€å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æã€‘")
    print("=" * 60)

    audio_file = "downloads/audio/ã€ç²—å“ã€‘æœ€è¿‘ã®SNSãƒ‹ãƒ¥ãƒ¼ã‚¹æ–¬ã£ãŸã€1äººè³›å¦ã€‘.wav"  # åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«

    if os.path.exists(audio_file):
        # åŸºæœ¬æƒ…å ±ã®åˆ†æ
        info = analyze_audio_file(audio_file)
        if info:
            print_audio_info(info)

        # ãƒ¬ãƒ™ãƒ«åˆ†æ
        level_info = analyze_audio_levels(audio_file)
        if level_info:
            print_level_analysis(level_info, Path(audio_file).name)

        # ãƒã‚¤ã‚ºæ¤œå‡º
        noise_info = detect_noise_types(audio_file)
        if noise_info:
            print_noise_detection(noise_info, Path(audio_file).name)

        # å‘¨æ³¢æ•°ç‰¹æ€§åˆ†æ
        freq_info = analyze_frequency_characteristics(audio_file)
        if freq_info:
            print_frequency_analysis(freq_info, Path(audio_file).name)

        # ç„¡éŸ³ãƒ»éŸ³å£°åŒºé–“åˆ†æ
        silence_info = analyze_silence_and_voice(audio_file, silence_thresh_db=-40.0)
        if silence_info:
            print_silence_analysis(silence_info, Path(audio_file).name)
    else:
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {audio_file}")

    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã™ã‚‹ä¾‹
    # print("\n" + "=" * 60)
    # print("ã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåˆ†æã€‘")
    # print("=" * 60)

    # directory = "wav_file"  # åˆ†æå¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    # results = analyze_directory(directory)

    # if results:
    #     generate_summary_report(results, "audio_analysis_report.txt")


if __name__ == "__main__":
    main()
